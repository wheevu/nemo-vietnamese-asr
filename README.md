# ğŸ™ï¸ End-to-End Vietnamese ASR System with NVIDIA NeMo

[![NeMo](https://img.shields.io/badge/NVIDIA-NeMo-green)](https://github.com/NVIDIA/NeMo) [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/) [![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)

## 1. Executive Summary

This project implements a complete **MLOps and Data Engineering pipeline** for Automatic Speech Recognition (ASR), specifically targeting low-resource languages (Vietnamese). The system automates the ingestion of unstructured audio-visual data from YouTube, performs ETL (Extract, Transform, Load) operations to create a clean speech corpus, and leverages cloud-based GPU infrastructure to deploy and evaluate enterprise-grade **Conformer-CTC** models using the **NVIDIA NeMo** framework.

The architecture solves the specific challenge of bridging a local **Apple Silicon (M1)** development environment with **Linux/CUDA** cloud training infrastructure, handling dependency management, cross-platform pathing, and robust data validation.

---

## 2. System Architecture

The system follows a hybrid **Local-to-Cloud** workflow designed for scalability and reproducibility.

![Architecture Diagram](./asset/mermaid-diagram.png)

---

## 3. ğŸ“‚ Project Structure

```bash
nemo-vietnamese-asr/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ yt_harvester/           # ğŸ“¦ Main Python package (Local ETL)
â”‚       â”œâ”€â”€ __init__.py         # Public API exports
â”‚       â”œâ”€â”€ __main__.py         # Entry point & orchestration
â”‚       â”œâ”€â”€ cli.py              # CLI argument parsing
â”‚       â”œâ”€â”€ config.py           # YAML configuration management
â”‚       â”œâ”€â”€ downloader.py       # YouTube data fetching logic
â”‚       â”œâ”€â”€ processor.py        # Text analysis (sentiment, keywords)
â”‚       â””â”€â”€ utils.py            # Helper functions
â”œâ”€â”€ prepare_data.py             # âš™ï¸ NeMo manifest generator & validator
â”œâ”€â”€ audio/                      # Output: 16kHz mono WAV files
â”œâ”€â”€ transcripts/                # Output: Clean raw transcript text
â”œâ”€â”€ structured_outputs/         # Output: Full metadata + analysis
â”œâ”€â”€ train_manifest.json         # NeMo training manifest
â””â”€â”€ NVIDIA_NeMo_ASR.ipynb       # â˜ï¸ Cloud Notebook (Training/Inference)
```

---

## 4. ğŸ› ï¸ Component 1: Local Data Engineering

The local engine (`src/yt_harvester`) is responsible for the **Extraction** and **Transformation** phases. It turns raw YouTube videos into structured datasets.

### Core Features

- **Smart Fallback Chain:** The `downloader.py` module attempts to fetch transcripts in the following order of quality:
  1.  Official Manual Transcripts (Vi/En)
  2.  Auto-Generated API Transcripts
  3.  Auto-Captions via `yt-dlp` CLI
- **Audio Standardization:** Automatically converts streams to **16kHz Mono WAV** (ASR Industry Standard) using FFmpeg post-processors.
- **Idempotency:** Checks for existing files before downloading to save bandwidth and enable safe re-runs.
- **Rich Metadata:** Extracts sentiment polarity and top keywords using `TextBlob` for potential future downstream tasks.

### CLI Usage

```bash
# 1. Harvest a single video (Audio + Metadata + Transcript)
python -m src.yt_harvester "https://www.youtube.com/watch?v=VIDEO_ID"

# 2. Bulk harvest from a list of links
python -m src.yt_harvester --bulk links.txt

# 3. Generate NeMo Manifests (Training/Validation/Test Split)
python prepare_data.py
```

### Manifest Generation Strategy (`prepare_data.py`)

This script acts as the **Validation Layer** before the cloud.

- **Integrity Check:** Scans all `.wav` files and cross-references them with `.txt` transcripts. If a transcript is missing or empty, the audio is automatically discarded to prevent training pollution.
- **Normalization:** Lowercases text and removes punctuation to match the CTC decoder's alphabet.
- **Splitting:** Performs a randomized 80/10/10 split for Train/Val/Test sets.

---

## 5. â˜ï¸ Component 2: Cloud Workflow (Google Colab)

**File:** `NVIDIA_NeMo_ASR_Training.ipynb`

This component handles **Model Loading, Inference, and Evaluation** using NVIDIA GPUs.

### Workflow Logic

1.  **Persistence Layer:**

    - Mounts Google Drive to act as a persistent file system.
    - Unzips the dataset from Drive to the local Colab VM disk (`/content/data`) for high-speed I/O access.

2.  **Model Loading (Universal Fix):**

    - Utilizes the polymorphic `ASRModel` class to load `stt_en_conformer_ctc_large` directly from the **NVIDIA NGC Catalog**. This resolves BPE vs. Char-based class mismatch errors encountered with older API methods.

3.  **Dynamic Path Bridging:**

    - The manifest files created on macOS contain paths like `/Users/josh/...`.
    - The notebook implements dynamic path correction logic to remap these to `/content/data/...` at runtime, enabling seamless cross-platform usage without rewriting files.

4.  **Inference Pipeline:**
    - **Segmentation:** Loads audio in 30-second chunks to avoid the $O(N^2)$ memory cost of Conformer self-attention, preventing OOM errors on the T4 GPU.
    - **Robust Decoding:** Adapts to NeMo v2.6.0 API signatures (`paths2audio_files` vs positional arguments) via try-catch blocks.

---

## 6. ğŸ“Š Results & Evaluation

To validate the pipeline integrity, a **Zero-Shot Inference** test was performed using the pre-trained English Conformer model on the Vietnamese dataset.

- **Metric:** Word Error Rate (WER) calculated via `jiwer`.
- **Quantitative Result:** WER â‰ˆ 1.00 (Expected for Zero-Shot English-on-Vietnamese).
- **Qualitative Analysis:** The model successfully demonstrated **Phonetic Mapping**, proving the neural network processed the acoustic features correctly.

| Original Vietnamese Audio | Model Transcription (English Phonetics) | Analysis                       |
| :------------------------ | :-------------------------------------- | :----------------------------- |
| **"Giang Æ i Radio"**      | _"the radio"_                           | âœ… Recognized English loanword |
| **"ChÃ o báº¡n"**            | _"ta bak"_                              | âœ… Acoustic approximation      |

**Conclusion:** The pipeline is fully functional and ready for Transfer Learning (Fine-Tuning) by freezing the encoder and retraining the decoder on the Vietnamese corpus.

---

## ğŸ“¦ Dependencies

- **Local:** `yt-dlp`, `ffmpeg`, `textblob`, `soundfile`, `pandas`
- **Cloud:** `nemo_toolkit[all]`, `pytorch-lightning`, `jiwer`, `librosa`
